{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Pré-processamento de Dados\n",
    ":label:`sec_pandas`\n",
    "\n",
    "Até agora, introduzimos uma variedade de técnicas para manipular dados que já estão armazenados em tensores.\n",
    "Para aplicar o *Deep Learning* na solução de problemas do mundo real,\n",
    "frequentemente começamos com o pré-processamento de dados brutos, em vez daqueles dados bem preparados no formato tensor.\n",
    "Entre as ferramentas analíticas de dados populares em Python, o pacote `pandas` é comumente usado.\n",
    "Como muitos outros pacotes de extensão no vasto ecossistema do Python,\n",
    "`pandas` podem trabalhar em conjunto com tensores.\n",
    "Então, vamos percorrer brevemente as etapas de pré-processamento de dados brutos com `pandas`\n",
    "e convertendo-os no formato tensor.\n",
    "Abordaremos mais técnicas de pré-processamento de dados em capítulos posteriores.\n",
    "\n",
    "## Lendo o  *Dataset*\n",
    "\n",
    "Como um exemplo,\n",
    "começamos (**criando um conjunto de dados artificial que é armazenado em um\n",
    "arquivo csv (valores separados por vírgula)**)\n",
    "`../ data / house_tiny.csv`. Dados armazenados em outro\n",
    "formatos podem ser processados de maneiras semelhantes.\n",
    "\n",
    "Abaixo, escrevemos o conjunto de dados linha por linha em um arquivo csv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "origin_pos": 1,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('NumRooms,Alley,Price\\n')  # Column names\n",
    "    f.write('NA,Pave,127500\\n')  # Each row represents a data example\n",
    "    f.write('2,NA,106000\\n')\n",
    "    f.write('4,NA,178100\\n')\n",
    "    f.write('NA,NA,140000\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 2
   },
   "source": [
    "Para [**carregar o conjunto de dados bruto do arquivo csv criado**],\n",
    "importamos o pacote `pandas` e chamamos a função` read_csv`.\n",
    "Este conjunto de dados tem quatro linhas e três colunas, onde cada linha descreve o número de quartos (\"NumRooms\"), o tipo de beco (\"Alley\") e o preço (\"Price\") de uma casa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley   Price\n",
      "0       NaN  Pave  127500\n",
      "1       2.0   NaN  106000\n",
      "2       4.0   NaN  178100\n",
      "3       NaN   NaN  140000\n"
     ]
    }
   ],
   "source": [
    "# Se o pandas ainda não estiver instalado descomente a linha abaixo:\n",
    "# !pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "## Lidando com Dados Faltantes\n",
    "\n",
    "Observe que as entradas \"NaN\" têm valores ausentes.\n",
    "Para lidar com dados perdidos, os métodos típicos incluem *imputação* e *exclusão*,\n",
    "onde a imputação substitui os valores ausentes por outros substituídos,\n",
    "enquanto a exclusão ignora os valores ausentes. Aqui, consideraremos a imputação.\n",
    "\n",
    "Por indexação baseada em localização de inteiros (`iloc`), dividimos os `dados` em `entradas` e `saídas`,\n",
    "onde o primeiro leva as duas primeiras colunas, enquanto o último mantém apenas a última coluna.\n",
    "Para valores numéricos em `entradas` que estão faltando,\n",
    "nós [**substituímos as entradas \"NaN\" pelo valor médio da mesma coluna.**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley\n",
      "0       3.0  Pave\n",
      "1       2.0   NaN\n",
      "2       4.0   NaN\n",
      "3       3.0   NaN\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "[**Para valores categóricos ou discretos em `entradas`, consideramos \"NaN\" como uma categoria.**]\n",
    "Como a coluna \"Alley\" aceita apenas dois tipos de valores categóricos \"Pave\" e \"NaN\",\n",
    "O `pandas` pode converter automaticamente esta coluna em duas colunas \"Alley_Pave\" e \"Alley_nan\".\n",
    "Uma linha cujo tipo de beco é \"Pave\" definirá os valores de \"Alley_Pave\" e \"Alley_nan\" como 1 e 0.\n",
    "Uma linha com um tipo de beco ausente definirá seus valores para 0 e 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  Alley_Pave  Alley_nan\n",
      "0       3.0           1          0\n",
      "1       2.0           0          1\n",
      "2       4.0           0          1\n",
      "3       3.0           0          1\n"
     ]
    }
   ],
   "source": [
    "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "## Convertendo para o Formato Tensor\n",
    "\n",
    "Agora que [**todas as entradas em `entradas` e `saídas` são numéricas, elas podem ser convertidas para o formato tensor.**]\n",
    "Uma vez que os dados estão neste formato, eles podem ser manipulados posteriormente com as funcionalidades de tensor que introduzimos em :numref:`sec_ndarray`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 1., 0.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 0., 1.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500, 106000, 178100, 140000]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "## Sumário\n",
    "\n",
    "* Como muitos outros pacotes de extensão no vasto ecossistema do Python, `pandas` pode trabalhar junto com tensores.\n",
    "* Imputação e exclusão podem ser usadas para lidar com dados perdidos.\n",
    "\n",
    "## Exercícios\n",
    "\n",
    "Crie um conjunto de dados bruto com mais linhas e colunas.\n",
    "\n",
    "3. Exclua a coluna com a maioria dos valores ausentes.\n",
    "4. Converta o conjunto de dados pré-processado para o formato tensor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/29)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "<!--stackedit_data:\n",
    "eyJoaXN0b3J5IjpbLTExMzIxNzgzOSwxMzkxNTMwMTQzLDIxMT\n",
    "Q3MzY2OTEsLTgxNTk0NzU2LC0xNDY1MTYwNjE2LC01MzU1NTgy\n",
    "NTBdfQ==\n",
    "-->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}