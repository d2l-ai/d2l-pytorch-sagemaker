{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Processamento de Linguagem Natural: Aplicações\n",
    ":label:`chap_nlp_app`\n",
    "\n",
    "\n",
    "Vimos como representar tokens de texto e treinar suas representações em :numref:`chap_nlp_pretrain`.\n",
    "Essas representações de texto pré-treinadas podem ser fornecidas a vários modelos para diferentes tarefas de processamento de linguagem natural *downstream*.\n",
    "\n",
    "Este livro não pretende cobrir as aplicações de processamento de linguagem natural de uma maneira abrangente.\n",
    "Nosso foco é *como aplicar a aprendizagem de representação (profunda) de idiomas para resolver problemas de processamento de linguagem natural*.\n",
    "No entanto, já discutimos várias aplicações de processamento de linguagem natural sem pré-treinamento nos capítulos anteriores,\n",
    "apenas para explicar arquiteturas de aprendizado profundo.\n",
    "Por exemplo, em :numref:`chap_rnn`,\n",
    "contamos com RNNs para projetar modelos de linguagem para gerar textos semelhantes a novelas.\n",
    "Em :numref:`chap_modern_rnn` e :numref:`chap_attention`,\n",
    "também projetamos modelos baseados em RNNs e mecanismos de atenção\n",
    "para tradução automática.\n",
    "Dadas as representações de texto pré-treinadas,\n",
    "neste capítulo, consideraremos mais duas tarefas de processamento de linguagem natural *downstream*:\n",
    "análise de sentimento e inferência de linguagem natural.\n",
    "Estes são aplicativos de processamento de linguagem natural populares e representativos:\n",
    "o primeiro analisa um único texto e o último analisa as relações de pares de texto.\n",
    "\n",
    "![As representações de texto pré-treinadas podem ser alimentadas para várias arquiteturas de *deep learning*  para diferentes aplicações de processamento de linguagem natural *downstream*. Este capítulo enfoca como projetar modelos para diferentes aplicações de processamento de linguagem natural *downstream*.](../img/nlp-map-app.svg)\n",
    ":label:`fig_nlp-map-app`\n",
    "\n",
    "\n",
    "Conforme descrito em :numref:`fig_nlp-map-app`,\n",
    "este capítulo se concentra na descrição das ideias básicas de projeto de modelos de processamento de linguagem natural usando diferentes tipos de arquiteturas de aprendizado profundo, como MLPs, CNNs, RNNs e atenção.\n",
    "Embora seja possível combinar qualquer representação de texto pré-treinada com qualquer arquitetura para qualquer tarefa de processamento de linguagem natural *downstream* em :numref:`fig_nlp-map-app`,\n",
    "selecionamos algumas combinações representativas.\n",
    "Especificamente, exploraremos arquiteturas populares baseadas em RNNs e CNNs para análise de sentimento.\n",
    "Para inferência de linguagem natural, escolhemos atenção e MLPs para demonstrar como analisar pares de texto.\n",
    "No final, apresentamos como ajustar um modelo BERT pré-treinado\n",
    "para uma ampla gama de aplicações de processamento de linguagem natural,\n",
    "como em um nível de sequência (classificação de texto único e classificação de par de texto)\n",
    "e um nível de *token* (marcação de texto e resposta a perguntas).\n",
    "Como um caso empírico concreto,\n",
    "faremos o ajuste fino do BERT para processamento de linguagem natural.\n",
    "\n",
    "Como apresentamos em :numref:`sec_bert`,\n",
    "BERT requer mudanças mínimas de arquitetura\n",
    "para uma ampla gama de aplicativos de processamento de linguagem natural.\n",
    "No entanto, esse benefício vem com o custo de um ajuste fino\n",
    "um grande número de parâmetros BERT para as aplicações *downstream*.\n",
    "Quando o espaço ou o tempo são limitados,\n",
    "aqueles modelos elaborados com base em MLPs, CNNs, RNNs e atenção\n",
    "são mais viáveis.\n",
    "A seguir, começamos pelo aplicativo de análise de sentimento\n",
    "e ilustrar o design do modelo baseado em RNNs e CNNs, respectivamente.\n",
    "\n",
    ":begin_tab:toc\n",
    " - [sentiment-analysis-and-dataset](sentiment-analysis-and-dataset.ipynb)\n",
    " - [sentiment-analysis-rnn](sentiment-analysis-rnn.ipynb)\n",
    " - [sentiment-analysis-cnn](sentiment-analysis-cnn.ipynb)\n",
    " - [natural-language-inference-and-dataset](natural-language-inference-and-dataset.ipynb)\n",
    " - [natural-language-inference-attention](natural-language-inference-attention.ipynb)\n",
    " - [finetuning-bert](finetuning-bert.ipynb)\n",
    " - [natural-language-inference-bert](natural-language-inference-bert.ipynb)\n",
    ":end_tab:\n",
    "\n",
    "<!--stackedit_data:\n",
    "eyJoaXN0b3J5IjpbLTE0MjEwMjQ2NzYsNDc5OTgzNzkzLDY5MD\n",
    "Y3MjA3MF19\n",
    "-->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}