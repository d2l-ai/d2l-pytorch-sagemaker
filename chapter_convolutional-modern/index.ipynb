{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Modern Convolutional Neural Networks\n",
    ":label:`chap_modern_cnn`\n",
    "\n",
    "Agora que entendemos o básico de conectar CNNs,\n",
    "vamos levá-lo por um tour pelas arquiteturas modernas da CNN.\n",
    "Neste capítulo, cada seção corresponde\n",
    "a uma arquitetura significativa da CNN que foi\n",
    "em algum ponto (ou atualmente) o modelo básico\n",
    "sobre o qual muitos projetos de pesquisa e sistemas implantados foram construídos.\n",
    "Cada uma dessas redes foi brevemente uma arquitetura dominante\n",
    "e muitos foram vencedores ou segundos classificados na competição ImageNet,\n",
    "que tem servido como um barômetro do progresso\n",
    "na aprendizagem supervisionada em visão computacional desde 2010.\n",
    "\n",
    "Esses modelos incluem AlexNet, a primeira rede em grande escala implantada a\n",
    "vencer os métodos convencionais de visão por computador em um desafio de visão em grande escala;\n",
    "a rede VGG, que faz uso de vários blocos repetidos de elementos; a rede na rede (NiN) que convolve\n",
    "redes neurais inteiras com patch por meio de entradas;\n",
    "GoogLeNet, que usa redes com concatenações paralelas;\n",
    "redes residuais (ResNet), que continuam sendo as mais populares\n",
    "arquitetura pronta para uso em visão computacional;\n",
    "e redes densamente conectadas (DenseNet),\n",
    "que são caros para calcular, mas estabeleceram alguns benchmarks recentes.\n",
    "\n",
    "Embora a ideia de redes neurais *profundas* seja bastante simples\n",
    "(empilhar um monte de camadas),\n",
    "o desempenho pode variar muito entre as arquiteturas e as opções de hiperparâmetros.\n",
    "As redes neurais descritas neste capítulo\n",
    "são o produto da intuição, alguns insights matemáticos,\n",
    "e muita tentativa e erro.\n",
    "Apresentamos esses modelos em ordem cronológica,\n",
    "em parte para transmitir um sentido da história\n",
    "para que você possa formar suas próprias intuições\n",
    "sobre para onde o campo está indo\n",
    "e talvez desenvolva suas próprias arquiteturas.\n",
    "Por exemplo,\n",
    "a normalização em lote e as conexões residuais descritas neste capítulo ofereceram duas ideias populares para treinar e projetar modelos profundos.\n",
    "\n",
    ":begin_tab:toc\n",
    " - [alexnet](alexnet.ipynb)\n",
    " - [vgg](vgg.ipynb)\n",
    " - [nin](nin.ipynb)\n",
    " - [googlenet](googlenet.ipynb)\n",
    " - [batch-norm](batch-norm.ipynb)\n",
    " - [resnet](resnet.ipynb)\n",
    " - [densenet](densenet.ipynb)\n",
    ":end_tab:\n",
    "\n",
    "<!--stackedit_data:\n",
    "eyJoaXN0b3J5IjpbODc1MTAyODQyLC0xMDkwNzQ0NzExXX0=\n",
    "-->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}